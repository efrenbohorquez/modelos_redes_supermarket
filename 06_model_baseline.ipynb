{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos Baseline - Ventas de Supermercado\n",
    "\n",
    "Este notebook implementa modelos baseline (línea base) para la predicción de ventas y otros indicadores clave en datos de supermercado. Estos modelos más simples, como Regresión Lineal y Árboles de Decisión, sirven como punto de comparación para evaluar el rendimiento de los modelos más complejos de redes neuronales.\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "1. Cargar y preparar los datos preprocesados\n",
    "2. Implementar modelos de Regresión Lineal\n",
    "3. Implementar modelos de Árboles de Decisión\n",
    "4. Implementar modelos de Gradient Boosting\n",
    "5. Evaluar y comparar el rendimiento de los modelos\n",
    "6. Analizar la importancia de características\n",
    "7. Guardar los modelos entrenados para su uso posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_palette('viridis')\n",
    "\n",
    "# Agregar directorio raíz al path para importar utilidades\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de Datos Preprocesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datasets preprocesados para modelos MLP (usaremos los mismos para los modelos baseline)\n",
    "try:\n",
    "    mlp_datasets = joblib.load('../data/processed/mlp_datasets.joblib')\n",
    "    print(\"Datasets para modelos baseline cargados correctamente.\")\n",
    "    \n",
    "    # Mostrar información de los datasets disponibles\n",
    "    print(f\"\\nDatasets disponibles: {list(mlp_datasets.keys())}\")\n",
    "    \n",
    "    for name, dataset in mlp_datasets.items():\n",
    "        print(f\"\\nDataset: {name}\")\n",
    "        print(f\"X_train shape: {dataset['X_train'].shape}\")\n",
    "        print(f\"X_test shape: {dataset['X_test'].shape}\")\n",
    "        print(f\"y_train shape: {dataset['y_train'].shape}\")\n",
    "        print(f\"y_test shape: {dataset['y_test'].shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: No se encontraron los datasets preprocesados. Ejecute primero el notebook de preprocesamiento.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de Utilidad para Modelos Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa un modelo baseline.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo de scikit-learn.\n",
    "        X_train, y_train, X_test, y_test: Datos de entrenamiento y prueba.\n",
    "        model_name (str): Nombre del modelo para identificación.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Resultados del entrenamiento y evaluación.\n",
    "    \"\"\"\n",
    "    # Entrenar modelo\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Predecir\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluar modelo\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Validación cruzada (opcional)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_rmse = np.sqrt(-cv_scores.mean())\n",
    "    \n",
    "    # Guardar resultados\n",
    "    results = {\n",
    "        'model': model,\n",
    "        'model_name': model_name,\n",
    "        'y_pred': y_pred,\n",
    "        'metrics': {\n",
    "            'mse': mse,\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'r2': r2,\n",
    "            'cv_rmse': cv_rmse\n",
    "        },\n",
    "        'training_time': training_time\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_feature_importance(model, feature_names, title=\"Importancia de Características\", top_n=15):\n",
    "    \"\"\"\n",
    "    Visualiza la importancia de características para modelos basados en árboles.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo entrenado (debe tener atributo feature_importances_).\n",
    "        feature_names (list): Nombres de las características.\n",
    "        title (str): Título para el gráfico.\n",
    "        top_n (int): Número de características principales a mostrar.\n",
    "    \"\"\"\n",
    "    if not hasattr(model, 'feature_importances_'):\n",
    "        print(\"El modelo no tiene atributo feature_importances_\")\n",
    "        return\n",
    "    \n",
    "    # Crear DataFrame con importancia de características\n",
    "    importance = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': model.feature_importances_\n",
    "    })\n",
    "    \n",
    "    # Ordenar por importancia\n",
    "    importance = importance.sort_values('Importance', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Mostrar top N características\n",
    "    top_importance = importance.head(top_n)\n",
    "    \n",
    "    # Visualizar\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=top_importance)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Importancia Relativa')\n",
    "    plt.ylabel('Característica')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return importance\n",
    "\n",
    "def plot_predictions(y_true, y_pred, title=\"Predicciones vs Valores Reales\"):\n",
    "    \"\"\"\n",
    "    Visualiza las predicciones vs valores reales.\n",
    "    \n",
    "    Args:\n",
    "        y_true (array): Valores reales.\n",
    "        y_pred (array): Valores predichos.\n",
    "        title (str): Título para el gráfico.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Gráfico de dispersión\n",
    "    plt.scatter(y_true, y_pred, alpha=0.5)\n",
    "    \n",
    "    # Línea de referencia (predicción perfecta)\n",
    "    min_val = min(np.min(y_true), np.min(y_pred))\n",
    "    max_val = max(np.max(y_true), np.max(y_pred))\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--')\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel('Valores Reales')\n",
    "    plt.ylabel('Predicciones')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de Modelos de Regresión Lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Regresión Lineal para Predicción de Ventas Totales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener datos para predicción de ventas totales\n",
    "dataset_name = 'ventas_totales'\n",
    "if dataset_name in mlp_datasets:\n",
    "    X_train = mlp_datasets[dataset_name]['X_train']\n",
    "    X_test = mlp_datasets[dataset_name]['X_test']\n",
    "    y_train = mlp_datasets[dataset_name]['y_train']\n",
    "    y_test = mlp_datasets[dataset_name]['y_test']\n",
    "    feature_names = mlp_datasets[dataset_name]['preprocessor']['feature_names']\n",
    "    \n",
    "    print(f\"Entrenando modelos de regresión lineal para {dataset_name}...\")\n",
    "    \n",
    "    # Crear y entrenar modelos\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Ridge Regression': Ridge(alpha=1.0),\n",
    "        'Lasso Regression': Lasso(alpha=0.1),\n",
    "        'ElasticNet': ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "    }\n",
    "    \n",
    "    # Resultados\n",
    "    linear_results = {}\n",
    "    \n",
    "    # Entrenar y evaluar cada modelo\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nEntrenando {name}...\")\n",
    "        results = train_and_evaluate_model(model, X_train, y_train, X_test, y_test, name)\n",
    "        linear_results[name] = results\n",
    "        \n",
    "        # Mostrar métricas\n",
    "        print(f\"MSE: {results['metrics']['mse']:.4f}\")\n",
    "        print(f\"RMSE: {results['metrics']['rmse']:.4f}\")\n",
    "        print(f\"MAE: {results['metrics']['mae']:.4f}\")\n",
    "        print(f\"R²: {results['metrics']['r2']:.4f}\")\n",
    "        print(f\"CV RMSE: {results['metrics']['cv_rmse']:.4f}\")\n",
    "        print(f\"Tiempo de entrenamiento: {results['training_time']:.4f} segundos\")\n",
    "        \n",
    "        # Visualizar predicciones\n",
    "        plot_predictions(y_test, results['y_pred'], \n",
    "                        title=f\"{name} - Predicciones vs Valores Reales ({dataset_name})\")\n",
    "    \n",
    "    # Comparar modelos de regresión lineal\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Modelo': [name for name in models.keys()],\n",
    "        'RMSE': [linear_results[name]['metrics']['rmse'] for name in models.keys()],\n",
    "        'MAE': [linear_results[name]['metrics']['mae'] for name in models.keys()],\n",
    "        'R²': [linear_results[name]['metrics']['r2'] for name in models.keys()],\n",
    "        'Tiempo (s)': [linear_results[name]['training_time'] for name in models.keys()]\n",
    "    })\n",
    "    \n",
    "    print(\"\\nComparación de modelos de regresión lineal:\")\n",
    "    print(metrics_df)\n",
    "    \n",
    "    # Visualizar comparación\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='Modelo', y='RMSE', data=metrics_df)\n",
    "    plt.title('Comparación de RMSE - Modelos de Regresión Lineal')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualizar coeficientes del mejor modelo\n",
    "    best_model_name = metrics_df.sort_values('RMSE').iloc[0]['Modelo']\n",
    "    best_model = linear_results[best_model_name]['model']\n",
    "    \n",
    "    if hasattr(best_model, 'coef_'):\n",
    "        coef_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Coefficient': best_model.coef_\n",
    "        })\n",
    "        \n",
    "        # Ordenar por valor absoluto de coeficiente\n",
    "        coef_df['Abs_Coefficient'] = np.abs(coef_df['Coefficient'])\n",
    "        coef_df = coef_df.sort_values('Abs_Coefficient', ascending=False).head(15)\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(x='Coefficient', y='Feature', data=coef_df)\n",
    "        plt.title(f'Top 15 Coeficientes - {best_model_name}')\n",
    "        plt.xlabel('Coeficiente')\n",
    "        plt.ylabel('Característica')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(f\"Error: No se encontró el dataset {dataset_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de Modelos de Árboles de Decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Árboles de Decisión para Predicción de Ventas Totales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener datos para predicción de ventas totales\n",
    "dataset_name = 'ventas_totales'\n",
    "if dataset_name in mlp_datasets:\n",
    "    X_train = mlp_datasets[dataset_name]['X_train']\n",
    "    X_test = mlp_datasets[dataset_name]['X_test']\n",
    "    y_train = mlp_datasets[dataset_name]['y_train']\n",
    "    y_test = mlp_datasets[dataset_name]['y_test']\n",
    "    feature_names = mlp_datasets[dataset_name]['preprocessor']['feature_names']\n",
    "    \n",
    "    print(f\"Entrenando modelos de árboles para {dataset_name}...\")\n",
    "    \n",
    "    # Crear y entrenar modelos\n",
    "    tree_models = {\n",
    "        'Decision Tree': DecisionTreeRegressor(max_depth=10, random_state=42),\n",
    "        'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42),\n",
    "        'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "    }\n",
    "    \n",
    "    # Resultados\n",
    "    tree_results = {}\n",
    "    \n",
    "    # Entrenar y evaluar cada modelo\n",
    "    for name, model in tree_models.items():\n",
    "        print(f\"\\nEntrenando {name}...\")\n",
    "        results = train_and_evaluate_model(model, X_train, y_train, X_test, y_test, name)\n",
    "        tree_results[name] = results\n",
    "        \n",
    "        # Mostrar métricas\n",
    "        print(f\"MSE: {results['metrics']['mse']:.4f}\")\n",
    "        print(f\"RMSE: {results['metrics']['rmse']:.4f}\")\n",
    "        print(f\"MAE: {results['metrics']['mae']:.4f}\")\n",
    "        print(f\"R²: {results['metrics']['r2']:.4f}\")\n",
    "        print(f\"CV RMSE: {results['metrics']['cv_rmse']:.4f}\")\n",
    "        print(f\"Tiempo de entrenamiento: {results['training_time']:.4f} segundos\")\n",
    "        \n",
    "        # Visualizar predicciones\n",
    "        plot_predictions(y_test, results['y_pred'], \n",
    "                        title=f\"{name} - Predicciones vs Valores Reales ({dataset_name})\")\n",
    "        \n",
    "        # Visualizar importancia de características\n",
    "        importance = plot_feature_importance(model, feature_names, \n",
    "                                           title=f\"Importancia de Características - {name}\")\n",
    "    \n",
    "    # Comparar modelos de árboles\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Modelo': [name for name in tree_models.keys()],\n",
    "        'RMSE': [tree_results[name]['metrics']['rmse'] for name in tree_models.keys()],\n",
    "        'MAE': [tree_results[name]['metrics']['mae'] for name in tree_models.keys()],\n",
    "        'R²': [tree_results[name]['metrics']['r2'] for name in tree_models.keys()],\n",
    "        'Tiempo (s)': [tree_results[name]['training_time'] for name in tree_models.keys()]\n",
    "    })\n",
    "    \n",
    "    print(\"\\nComparación de modelos de árboles:\")\n",
    "    print(metrics_df)\n",
    "    \n",
    "    # Visualizar comparación\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='Modelo', y='RMSE', data=metrics_df)\n",
    "    plt.title('Comparación de RMSE - Modelos de Árboles')\n",
    " 
(Content truncated due to size limit. Use line ranges to read in chunks)